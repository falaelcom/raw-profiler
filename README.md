MAIN FEATURES
==================================================

- **Measuring and logging of sync and async code execution times**, based on manually placed profiling API function calls.
- **Execution statistics** collecting and logging - execution counters, min, average, max and total execution times, CPU usage during execution and various OS CPU and memory usage stats.
- **Suitable for production environments** - enable and disable profiling **_without restarting_** the application (see below). 
- **_Zero performance overhead_** when profiling is disabled.
- **Use with heavy server loads _with no performance impact_** - easy to set up **remote logging** via HTTP.
- **Centralized logging** - redirect the logging and profiling feed from all your web servers towards a single logging server.
- **Detection** and reporting of never-ending profiling incidents.
- **Monitor** the current statistics, **examine** full stats history.
- **Structure** the stats into profiling buckets for easier analysis.
- **Extensible** - provides easy ways to create custom loggers and data collector proxies.
- **Configurable logging memory queue** with delayed fs writing operations, implemented as part of the default file logger.
- **Automatic compression** of log files.
- **Automatic removal** of archive files.
- **Easy and simple** - minimal code is required to set up and profile.

GLOSSARY
==================================================

- **Profiling hit** - a single profiling incident that starts or ends a time measurment between a `__pfbegin` function call and it's paired `__pfend`.
- **Profiling hit point** - a place in the application code where some profiling begins, marked by a `__pfbegin` function call
- **Profiling bucket** - a single profiling bucket usually corresponds to a single profiling hit point in the code, for Ex. `"CRUD"`, `"ExpressRequests"`, `"RPC"`, `"VerySpecificSuspiciousLoop"`. The profiling bucket names are predefined and hardcoded by the developer, and their amount is fixed during application execution. The bucket name `"header"` is reserved and should never be used.
- **Profiling key** - a dynamically generated name for the specific profiling hit, for Ex., under the `"CRUD"` bucket, possible profiler keys could be `"READ user [_id]"` or `"CREATE patient [name,email,ssn,password]"`. The profiling keys are dynamically generated during the application execution and their amount increases over time. Actual stats are collected per profiling key.
- **Profiling hit title** - this text will be printed as a part of the heading of the stats table for a single hit (give it a try to get a better idea).
- **Profiling hit last message** - this text, which is provided at the hit's end, will be appended to the hit title.
- **Local profiling** - all statistics formatting and logging is done on the application server; the time taken for formatting of statistics and logging affects the application pefrormance and can interfere with the profiling results.
- **Remote profiling** - the profiler performs only measurments and simple mathematical operations on the application server, forwarding the results to a remote machine (the profiler data collector); all statistics formatting and logging is done on the remote server; the time taken for formatting of statistics and logging no more affects the application pefrormance and the profiling results are clean.

HOW TO SET UP PROFILING
==================================================

Setup For Local Console Logging
--------------------------------------------
_Appropriate for simple profiling scenarios with a single bucket._

In the application main file (e.g. app.js), add

    require("mc-profiler");


Setup For Local Logging To The File System
--------------------------------------------
_Appropriate for profiling scenarios with multiple buckets under lower server loads._

In the application main file (e.g. app.js), add

    require("mc-profiler");
    __pfconfig({logger: __pf.FsLogger, logDelayMs: 4000});

    //	will store the profiler output in the ~/__pflogs directory; will flush the output every 4 seconds


To create a file logger with custom params, use

    require("mc-profiler");
	__pfconfig({logger: __pf.createFileLogger(
	{
		source: "MyAppInstance",
		logDirectory: "/var/logs/mc-profiler",
		maxLogSizeBytes: 1024 * 1024,
		maxArchiveSizeBytes: 200 * 1024 * 1024,
	})});

    //  will store the profiler output in the /var/logs/mc-profiler/MyAppInstance directory
    //  the output won't be delayed
    //  will monitor the total size of all *.log files, generated by the current profiling session
    //      when the total size exceeds 1024 * 1024 bytes (1Mb), all *.log files will be moved to a zip-file
    //  will monitor the total size of all *.zip files in the archive directory
    //      when the total size exceeds 200 * 1024 * 1024 bytes (200Mb), the oldest archive files will be removed


Setup For Remote Logging
--------------------------------------------
_Appropriate for profiling scenarios with heavy server loads._

In the application main file (e.g. app.js), add

    require("mc-profiler");
    __pfconfig({dataCollector: __pf.createDataCollectorHttpProxy("http:127.0.0.1:9666/feed", "node1"), requestTimeoutMs: 5000});

    //	will proxy the stats to a remote server
    //  will timeout outgoing logging requests in 5000 ms (default is 2000 ms)
    //	the remote server will append "-node1" to the name of the subdirectory that will strore the logs from this particular application instance
    //	this way one logging server can collect data from many application instances


To start the remote profiling data collector server, create a new app.js file, like this

    require("mc-profiler");
    __pf.createDataCollectorServer({host: "<ip/host to listen on>", port: "9666", logDelayMs: 300}).run();


In order to perform custom feed source detection, run the remote profiling data collector server like this

     require("mc-profiler");
     __pf.createDataCollectorServer({host: "<ip/host to listen on>", port: "9666", logDelayMs: 300}).run(function(req, res)
     {
        return req.headers["x-forwarded-for"] ||
            req.headers["x-real-ip"] ||
            req.connection.remoteAddress ||
            req.socket.remoteAddress ||
            req.connection.socket.remoteAddress;
     });


You may need to install several npm modules, before the server starts successfully.

Start the server with

    node app


Automatic Log File Compression And Archiving With Local Profiling
--------------------------------------------
Intensive profling tends to generate huge logs, which could easily reach gigabytes per hour in production environments. Enabling the automatic log file compression and archiving
mitigates this effect to some extent.


To enable the automatic log file compression and archiving for local profiling, specify the `maxLogSizeBytes` parameter for the file logger (`0` - disabled; `> 0` - enabled). In the application main file (e.g. app.js), add

    require("mc-profiler");
    __pfconfig({logger: __pf.createFileLogger({maxLogSizeBytes: 1024 * 1024}), logDelayMs: 4000});

    //  will monitor the total size of all *.log files, generated by the current profiling session
    //      when the total size exceeds 1024 * 1024 bytes (1Mb), all *.log files will be moved to a zip-file


The file logger may be instructed to store the raw log files in a custom directory by providing an absolute path or a path, relative to the home directory of the user who runs the app:

    require("mc-profiler");
    __pfconfig({logger: __pf.createFileLogger({logDirectory: "/var/logs/mc-profiler", maxLogSizeBytes: 1024 * 1024}), logDelayMs: 4000});


The file logger is able to prevent the total archive size from exceeding a certain value (by automatically deleting oldest archive (`*.zip`) files):

    require("mc-profiler");
    __pfconfig({logger: __pf.createFileLogger({logDirectory: "/var/logs/mc-profiler", maxLogSizeBytes: 1024 * 1024, maxArchiveSizeBytes: 10 * 1024 * 1024}), logDelayMs: 4000});

    //	will set the max uncompressed log size to 1Mb
    //	will set the max archive size to 10Mb


Automatic Log File Compression And Archiving With Remote Profiling
--------------------------------------------
_See also the previous section._ The automatic log file compression and archiving is enabled by default on the profiling data collector server, with `maxLogSizeBytes` set to `200Mb`.


To change the `maxLogSizeBytes` value, create the profiling data collector server app.js file using:

    require("mc-profiler");
    __pf.createDataCollectorServer({host: "<ip/host to listen on>", port: "9666", logDelayMs: 300, maxLogSizeBytes: 500 * 1024, maxArchiveSizeBytes: 10 * 1024 * 1024}).run();

    //	will set the max uncompressed log size to 500Kb
    //	will set the max archive size to 10Mb


The profiling data collection server may be instructed to store the raw log files in a custom directory by providing an absolute path or a path, relative to the home directory of the user who runs the app:

    require("mc-profiler");
    __pf.createDataCollectorServer({host: "<ip/host to listen on>", port: "9666", logDelayMs: 300, logDirectory: "/var/logs/mc-profiler"}).run();

    //	will use /var/logs/mc-profiler to store current log files


Placing Profiling Hit Points In Code
--------------------------------------------
In the code, use `__pfbegin` and `__pfend` to profile

    var hit = __pfbegin("bucketName1", "keyName1" [, "title"]);
    ... //	synchronous or asynchronous code
    __pfend(hit [, " append to title"]);


Use `if(__pfenabled()) {...  /* profiling code */ }` to prevent large portions of profiling code from executing when profiling is disabled (usually code that builds profiler keys), e.g.

    var hit;
    if(__pfenabled())
    {
        var sb = [];
        sb.push("READ");
        sb.push(collectionName);
        sb.push(__pf.utility.getKeysText(query));
        hit = __pfbegin("CRUD", sb.toString(" "), "query=" + query);
    }
    ...
    if(__pfenabled())
    {
        __pfend(hit, err ? "; error=" + err : "");
    }

Use `if(__pfenabled("<bucketName>"))` to check if a specific bucket is enabled.


To aid building schema-specific profiling keys for `_pfbegin`, use

	var keysText = __pf.utility.getKeysText(data);   //	if data == {a: 1, b: {c: 1}}, keysText will be "a,b"


`keysText` can be appended to profiling keys to add schema specificity, for Ex., when profiling CRUD operations, one could build the profiling key by combining the _db operation type_ (read, insert...), the _db collection name_ and a `keysText` based on the query, e.g.:

    "READ calendar_event [event_type,user]"


`_pfbegin` may be used also for logging. To strip sensitive data from a javascript object you would like to append to the log, you can use `__pf.utility.stripStringify(obj, stripFieldNames)`:

	__pf.utility.stripStringify(data, ["password", "deletedObject.password"]);


This function accepts both objects and arrays as its first argument. It sets all designated fields to `"(stripped by mc-profiler)"` and returns a `JSON.stringify` of the object. `__pf.utility.stripStringify` does not modify the original object.


Enabling and disabling the profiler
--------------------------------------------
The profiler can be enabled and disabled without restarting the application server. To enable profiling, create the file `~/__pfenable` on the application server, to disable profiling, delete/rename the file `~/__pfenable`.


Profiler runtime preferences (`__pfconfig`)
--------------------------------------------
The profiler's runtime preferences are loaded from the `~/__pfconfig` file. To edit the runtime preferences use the command

	nano ~/__pfconfig


Sample config file:

	{
		"sortColumn": "totalMs",
		"archivePath": "/media/archive",
		"verbosity": "brief",
		"buckets":
		{
			"myBucket":
			{
				"enabled": false,
			},
			"myBucket2":
			{
				"sortColumn": "total",
			}
		}
	}


The following configuration fields are supported:

- `sortColumn` - specifies the key of the stats table column to perform sorting on. `sortColumn` must be a name of a numeric data column, one of the following:

        count
        discrepancy
        minMs
        avgMs
        maxMs -> default
        totalSec
        totalMs
        avgCpu
        minAvgOsCpu
        avgAvgOsCpu
        maxAvgOsCpu

- `archivePath` - points to the directory where the log archive zip-files will be stored. When the field is not specified, the zip-files are created in the same directory as the log files. In order to save newly created zip-files to another location, provide as a value an absolute path or a path that is relative to the home directory of the user who runs the application.

- `verbosity` - defines the level of output verbosity. The possible values are enumerated in `__pf.enums.EVerbosity`:

	- `__pf.enums.EVerbosity.Full = "full" -> default` - will print full profiling stats for each profiling hit
	- `__pf.enums.EVerbosity.Brief = "brief"` - will print tables with summary and info only for the current hit profiling key
	- `__pf.enums.EVerbosity.Log = "log"` - won't print tables, only timestamped titles


- `buckets` - provides control over which buckets are enabled for logging and lets you override per bucket the default sorting column preference:

		"buckets":
		{
			"myBucket":
			{
				"enabled": false,
			},
			"myBucket2":
			{
				"sortColumn": "total",
			}
		}

By default all buckets are enabled and all buckets use the default sorting column.

_The changes in the preferences from `~/__pfconfig` will apply on the next profiling hit._


READING LOCAL PROFILING RESULTS
==================================================

- Enable profiling for the first time (works only on the application server)

		user@appServer$ touch ~/__pfenable

- Disable profiling (works only on the application server)

		user@appServer$ mv ~/__pfenable ~/__pfenable.not

- Reenable profiling (works only on the application server)

		user@appServer$ mv ~/__pfenable.not ~/__pfenable

- Monitor bucket output with local profiling

		user@appServer$ watch cat ~/__pflogs/bucketName1.now

- See full profiling history with local profiling

		user@appServer$ less ~/__pflogs/bucketName1.log
		or
		user@appServer$ less ~/__pflogs/<timestamp>-bucketName1.log       # with automatic log file compression and archiving


- Change current sorting column with local profiling

		user@appServer$ nano ~/__pfconfig


READING REMOTE PROFILING RESULTS
==================================================

- Monitor bucket output with remote profiling

		user@profilingServer$  watch cat ~/__pflogs/<app-server-ip>-<source-name>/bucketName1.now


- See full profiling history with remote profiling

		user@profilingServer$ less ~/__pflogs/<app-server-ip>-<source-name>/bucketName1.log
		or
		user@profilingServer$ less ~/__pflogs/<app-server-ip>-<source-name>/<timestamp>-bucketName1.log       # with automatic log file compression and archiving


- Change current sorting column with remote profiling

		user@profilingServer$ $ nano ~/__pfconfig


STATS TABLE COLUMNS
==================================================

- `key` - the name of the profiling key
- `count` - the count of profile hits for the specified key; _sorting column name: `count`_
- `d.` - "discrepancy". values other than 0 indicate incidents of a profiling hit point that has been hit, but never ended (the corresponding `__pfend` has not been calld yet); the value represents the number of such pending hits; it's normal to see such indications from time to time appear and disappear; a problem could be recognized, if such indications last for longer times; _sorting column name: `discrepancy`_
- `minms` - the shortest execution time for the specified key on record; _sorting column name: `minMs`_
- `avgms` - the average execution time for the specified key since the profiling has started; _sorting column name: `avgMs`_
- `maxms` - the longest execution time for the specified key on record; _sorting column name: `maxMs`_
- `totalms` - the total execution time for the specified key since the profiling has started; _sorting column names: `totalSec`, `totalMs`_
- `max event time` - the timepoint at which the value from `maxms` was recorded
- `CPU%` - the load of the OS CPU during the hit duration; if multiple CPUs are reported by the OS, the highest value is taken; it is normal for this value to be close to 100% - this means that during the profiling hit the application's main thread did not wait; _sorting column name: `avgCpu`_
- `minCPU%` - the minimum OS CPU load, measured for the last 1 minute at the end of a profiling hit for the specified key (this value has no direct relation to the `CPU%` value); _sorting column name: `minAvgOsCpu`_
- `avgCPU%` - the average OS CPU load, measured for the last 1 minute since the profiling has started for the specified key (this value has no direct relation to the `CPU%` value); _sorting column name: `avgAvgOsCpu`_
- `maxCPU%` - the maximum OS CPU load, measured for the last 1 minute at the end of a profiling hit for the specified key (this value has no direct relation to the `CPU%` value); _sorting column name: `maxAvgOsCpu`_

SUBHEADER TABLE COLUMNS
==================================================

The profiler counts all profiling hits globally (**N**) and **locally** (per profiling key, **LN**). It also keeps track of all currently **open** hits, i.e. hits that did start but did not end yet.

- `delta LN` - how many other hits of the same profiling key occured during the current hit's time
- `->LN` - the local hit count at the time the current hit started
- `LN->` - the local hit count at the time the current hit ended
- `delta N` - how many other hits of any profiling key occured during the current hit's time
- `->N` - the global hit count at the time the current hit started
- `N->` - the global hit count at the time the current hit ended
- `delta open` - the delta between the `->open` and `open->` values
- `->open` - how many hits have stared but haven't ended when the current hit started
- `open->` - how many hits have stared but haven't ended when the current hit ended
- `duration` - the duration of the current profiling hit
- `CPU%` - the average OS CPU load during profiling hit's execution (100% is ok, this means that the application hasn't waited during the hit)

NOTES
==================================================

- All file paths used by the profiler are relative to the home directory of the user who runs the application.
- All functions used for profiling are synchronous (`__pfbegin`, `__pfend`, `__pfenabled`).
- Writing logs is asynchronous (no thread blocking with IO operations).
- Use multiple profiling buckets to split the profiler output into separate tables / files.
- Disabling the profiler by deleting/renaming the file `~/__pfenable` will retain all profiling stats and won't delete the `*.log` and `*.now` files. Enabling the profiler will continue from where it left off.
- Enabling and disabling the profiler via `~/__pfenable` works only on the application server and not on the remote data collector server. On the remote data collector server the `~/__pfenable` file is ignored.
- With local profiling, the loggers use the sorting column, specified in `~/__pfconfig` on the **application** server.
- With remote profiling, the loggers use the sorting column, specified in `~/__pfconfig` on the **remote data collector server** (in which case the app server sorting column preference is ignored).
- Multiple applications/node instances can feed towards the same data collector server; different sources will be differentiated based on the feed source server's IP, combined with the feed source server's sourceName setting.
- When the automatic log file compression and archiving is enabled, the naming of the log files changes from `~/__pflogs/[<app-server-ip>-<source-name>/]bucketName1.log` to `~/__pflogs/[<app-server-ip>-<source-name>/]<timestamp>-bucketName1.log`. The timestamp is regenerated every time the current log files are moved to a zip file. The zip file names correspond to the timestamp of the archived log files and can be used for sorting (zip-files with larger numbers in names are generated later).
- When the automatic log file compression and archiving is enabled, orphaned log files are archived automatically - hit the logs directory is periodically checked for *.log files with a time stamp in the name that does not match the current time stamp; all such files are zipped to a file named `<timestamp>-orphaned.zip` and deleted.

CHANGES
==================================================
1.1.14 -> 1.1.16

- Fixed a bug preventing the profiler in remote logging scenarios from rereading modified configuration at the application's side.
- Fixed a bug that made the whole profiler data to be reset on every hit when at least one bucket is disabled.

1.1.12 -> 1.1.14

- When included, the profiler starts its own system and process resources monitoring timer with resolution 5s. The collected stats are used profiling, but are also available at any time via __pf.Profiler.osResourceStats:

	- `__pf.Profiler.osResourceStats.avgCpu10sec` - OS CPU average for 10 s time window;
	- `__pf.Profiler.osResourceStats.avgCpu1min` - OS CPU average for 1 min time window;
	- `__pf.Profiler.osResourceStats.avgCpu5min` - OS CPU average for 5 min time window;
	- `__pf.Profiler.osResourceStats.avgCpu15min` - OS CPU average for 15 min time window;

	- `__pf.Profiler.osResourceStats.psCpuUsage` - {system: 0, user: 0} or the return value of process.cpuUsage(), if this method is supported;
	- `__pf.Profiler.osResourceStats.psMemUsage` - the return value of process.memoryUsage();

	- `__pf.Profiler.osResourceStats.psUptime` - the return value of process.uptime(),
	- `__pf.Profiler.osResourceStats.osUptime` - the return value of os.uptime(),

All values are updated every 5 seconds. Using cached values prevents the nodejs process from exhausting available file descriptors on extremely heavy server loads (every sytem/process resource check is done by reading from a /proc/* or /sys/* or /dev/* file).
Because of the caching, the RAM deltas reported in log files are no more precise (the 5s update resolution is way too large for a typical profiling hit), but can be informative when profiling long-lasting processes.
- Fixed configuration problem (missing `sortColumn` property from bucket settings caused an error).

1.1.10 -> 1.1.12

- Now profiling can be disabled per bucket from the `__pfconfig` file. (Previously this setting only affected the logging). `__pfenabled` now accepts a bucket name as an optional argument.

1.1.10 -> 1.1.11

- Documentation clean-up.

1.1.5 -> 1.1.10

- Replaced os load avg stats with real cpu stats (previously the loadavg()-stats were wrongly reported as percentage)
- Custom request timeout can now pe specified as a field in the `__pfconfig` function call, like this: `__pfconfig({dataCollector: __pf.createDataCollectorHttpProxy("http://127.0.0.1:9666/feed", config.environment), requestTimeoutMs: 5000});`
- Flushing the collected data to the logger and especiallty to the file logger now works asynchrounously, preventing request timeouts with remote logging under heavy application loads.
- Fixed the broken order of logging, which was inroduced by the async file logger
- Now detects and logs also 503 bad gateway errors from the data collecting server

1.1.0 -> 1.1.5

- Documentation changes.
- Now the data collection proxy accept a second parameter: `sourceName`. If `sourceName` is set, the data collection server will append a stripped version of this string to the logging subdirectory, e.g. it will use `127.0.0.1-development` instead of the plain `127.0.0.1`.
- System message format changes.
- Added a new parameter `logRequestArchivingModulo` to `__pf.createFileLogger` (with default value `25`) and `__pf.createDataCollectorServer` (with default value `100`). This value causes the file logger to try to archivate current log files on every `logRequestArchivingModulo`-th logging request rather than on every logging request (previous behavior).
- FIXED: was ignoring the `archivePath` setting.

1.0.11 -> 1.1.0

- To determine the feed source, the remote logger used `req.headers["x-real-ip"]`; now the feed source detection can be outsourced to a callback. The default behavior with no callback is (with some sugar to avoid null-reference errors):

	`source = req.connection.remoteAddress || req.socket.remoteAddress || req.connection.socket.remoteAddress || "";`

- The profiler preferences are now stored in a file named `__pfconfig` rather then in `__pfenable`. The `__pfenable` file is now solely used to enable/disable profiling.
- Better file archiving error handling.
- Now all `console.log` messages generated by mc-profiler are prefixed with `[mc-profiler] `.
- Added to `__pfconfig` a new configuration field `archivePath`. When the field is not specified, the log archive zip-files are created in the same directory as the log files. In order to save newly created log archive zip-files to another location, provide an absolute path or a path that is relative to the home directory of the user who runs the application.
- Added to `__pfconfig` a new configuration field `verbosity` (default = `"full"`). The possible values are enumerated in `__pf.enums.EVerbosity = { Log: "log", Brief: "brief", Full: "full" }`.
- Added to `__pfconfig` a new configuration field `buckets`, which provides control over which buckets are enabled for logging and lets you override per bucket the default sorting column preference.
- Added automatic orphaned log file archiving (only if archiving is enabled) - on every profiling hit the logs directory is checked for `*.log` files with a time stamp in the name that does not match the current time stamp; all such files are moved to an archive named `<timestamp>-orphaned.zip`.
- Console logger now prints only the current bucket (like the file logger).
- The current profiling key now has a `"> "` mark in the printed tables.
- Added documentation on the subheader table cryptic column names (`delta LN`, `->LN` etc).
- Fixed the excessive error logging on connection fail (with remote logging). Now data feed request errors will be reported once every 15 seconds.
- The data feed request is now made within a `setImmediate` call.
- Now the oldest archive files are automatically deleted when the total archive size reaches a certain limit.
- Will no more delete `*.now` files after archiving.
- Added a last message text to the `__pfend` params. The last message will be appended to the title, provided in the `pfbegin` call.
- Now the __pf* public methods never throw exceptions (but log all exceptions to the console).
- Added a new utlity function `__pf.utility.stripStringify(obj, stripFieldNames);`, intended to strip sensitive data from a javascript object you would like to append to the log.

TODO
==================================================

- The CPU usage is being calculated based on OS and not node js process CPU stats (older node js versions lack a required api). Desired solution - detect node js version and enable node js process CPU stats when possible.
- Add disk space and log size stats to the bucket table headers.
- Code
	- Better code structure - the project has grown over time and needs clean-up and better structure
	- Cache hit.bucket + "*" + hit.key in the hit
- Configuration
	- Provide same configuration options from code (the `__pfconfig` function call) and from file (the `__pfconfig` file JSON).
	- Add logging directory configuration for all scenarios (currently implemented only for the data collector server).
	- Add configuration for the DataCollectorHttpProxy's failureTimeoutMs (Currently fixed at 15s).
- Documentation
	- Better documentation structure (add separate sections for every major component)
	- Add a "HOW TO EXTEND" documentation topic.
- Known problems
	- Orphaned file archives can have too recent time signatures in the names.

LICENSE
==================================================

GNU General Public License _(see the included LICENSE file)_.

BUG REPORTS
==================================================

Send bug reports and suggestions to <daniel.apostolov@practicedent.com>.

